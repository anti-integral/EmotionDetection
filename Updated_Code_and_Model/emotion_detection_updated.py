# -*- coding: utf-8 -*-
"""Emotion_Detection_Updated.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qo4Zk0H-yyEnCivYfOjEm-5HCMG9eWRs
"""

pip install scikit-plot

from google.colab import drive
drive.mount('/content/drive')

import math
import numpy as np
import pandas as pd
import os
import cv2

import scikitplot
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report

import tensorflow as tf
from tensorflow.keras import optimizers
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D
from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation
from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from keras.utils import np_utils
from PIL import Image, ImageDraw

data_dir = "/content/drive/MyDrive/Testing"

cls = ["0", "1", "2", "3", "4", "5", "6"]

for category in cls:
  path = os.path.join(data_dir, category)
  for img in os.listdir(path):
    img_array = cv2.imread(os.path.join(path, img))
    plt.imshow(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))
    plt.show()
    break
plt.show()

img_size = 224
new_array = cv2.resize(img_array, (img_size, img_size))
plt.imshow(cv2.cvtColor(new_array, cv2.COLOR_BGR2RGB))
plt.show()

#read and convert images to array

t_Data = []

def create_training_Data():
  for category in cls:
    path = os.path.join(data_dir, category)
    class_num = cls.index(category)
    for img in os.listdir(path):
      try: 
        img_array = cv2.imread(os.path.join(path,img))
        new_array= cv2.resize(img_array, (img_size, img_size))
        t_Data.append((new_array, class_num))
      except Exception as e:
        pass

create_training_Data()

print(len(t_Data))

temp = np.array(t_Data)

temp.shape

import random

random.shuffle(t_Data) #ensuring my model does not learn the sequece

X = []
Y = []

for features, label in t_Data:
  X.append(features)
  Y.append(label)

X = np.array(X).reshape(-1, img_size, img_size, 3)

X = X/255.0 #normalize data on a scale of 0 to 1

yy = np.array(Y)
yy = np.array(list([[0 if k!=yy[j] else 1  for k in range(7)] for j in range(len(yy))]))
yy.shape

def build_net(optim):
#DCNN Network
    net = Sequential(name='DCNN')

    net.add(
        Conv2D(
            filters=64,
            kernel_size=(5,5),
            input_shape=(224, 224, 3),
            activation='elu',
            padding='same',
            kernel_initializer='he_normal',
            name='conv2d_1'
        )
    )
    net.add(BatchNormalization(name='batchnorm_1'))
    net.add(
        Conv2D(
            filters=64,
            kernel_size=(5,5),
            activation='elu',
            padding='same',
            kernel_initializer='he_normal',
            name='conv2d_2'
        )
    )
    net.add(BatchNormalization(name='batchnorm_2'))
    
    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))
    net.add(Dropout(0.4, name='dropout_1'))

    net.add(
        Conv2D(
            filters=128,
            kernel_size=(3,3),
            activation='elu',
            padding='same',
            kernel_initializer='he_normal',
            name='conv2d_3'
        )
    )
    net.add(BatchNormalization(name='batchnorm_3'))
    net.add(
        Conv2D(
            filters=128,
            kernel_size=(3,3),
            activation='elu',
            padding='same',
            kernel_initializer='he_normal',
            name='conv2d_4'
        )
    )
    net.add(BatchNormalization(name='batchnorm_4'))
    
    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))
    net.add(Dropout(0.4, name='dropout_2'))

    net.add(
        Conv2D(
            filters=256,
            kernel_size=(3,3),
            activation='elu',
            padding='same',
            kernel_initializer='he_normal',
            name='conv2d_5'
        )
    )
    net.add(BatchNormalization(name='batchnorm_5'))
    net.add(
        Conv2D(
            filters=256,
            kernel_size=(3,3),
            activation='elu',
            padding='same',
            kernel_initializer='he_normal',
            name='conv2d_6'
        )
    )
    net.add(BatchNormalization(name='batchnorm_6'))
    
    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))
    net.add(Dropout(0.5, name='dropout_3'))

    net.add(Flatten(name='flatten'))
        
    net.add(
        Dense(
            128,
            activation='elu',
            kernel_initializer='he_normal',
            name='dense_1'
        )
    )
    net.add(BatchNormalization(name='batchnorm_7'))
    
    net.add(Dropout(0.6, name='dropout_4'))
    
    net.add(
        Dense(
            7,
            activation='softmax',
            name='out_layer'
        )
    )
    
    net.compile(
        loss='categorical_crossentropy',
        optimizer=optim,
        metrics=['accuracy']
    )
    
    net.summary()
    
    return net

#In my old code, I experienced a lot of issues that were a result of overfitting
#and used this code to help prevent my model from overfitting

early_stopping = EarlyStopping(
    monitor='val_accuracy',
    min_delta=0.00005,
    patience=11,
    verbose=1,
    restore_best_weights=True,
)

lr_scheduler = ReduceLROnPlateau(
    monitor='val_accuracy',
    factor=0.5,
    patience=7,
    min_lr=1e-7,
    verbose=1,
)

callbacks = [
    early_stopping,
    lr_scheduler,
]

train_datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.15,
    height_shift_range=0.15,
    shear_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True,
)
train_datagen.fit(X)

from keras.callbacks import ModelCheckpoint
checkpoint_path = "/content/drive/MyDrive/Tests/"
checkpoint_dir = os.path.dirname(checkpoint_path)

cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)

optims = [
    optimizers.Nadam(learning_rate=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),
    optimizers.Adam(0.005),
]
# I tried both `Nadam` and `Adam`, the difference in results is not different but I finally went with Nadam as it is more popular.
model = build_net(optims[1])
checkpoint = [ModelCheckpoint(filepath='model.h5')]
history = model.fit_generator(
    train_datagen.flow(X, yy, batch_size=32), #batch size of 32 performs the best
    validation_data=(X, yy),
    steps_per_epoch=len(X) / 32,
    epochs=210,
    callbacks=[cp_callback],
    use_multiprocessing=True
)

model_yaml = model.to_json()
with open("model.yaml", "w") as yaml_file:
    yaml_file.write(model_yaml)
    
model.save("fModel.h5")

model.save("finalModel.h5")

df_accu = pd.DataFrame({'train': history.history['accuracy'], 'valid': history.history['val_accuracy']})
df_loss = pd.DataFrame({'train': history.history['loss'], 'valid': history.history['val_loss']})

fig = plt.figure(0, (14, 4))
ax = plt.subplot(1, 2, 1)
sns.violinplot(x="variable", y="value", data=pd.melt(df_accu), showfliers=False)
plt.title('Accuracy')
plt.tight_layout()

ax = plt.subplot(1, 2, 2)
sns.violinplot(x="variable", y="value", data=pd.melt(df_loss), showfliers=False)
plt.title('Loss')
plt.tight_layout()

plt.savefig('performance_dist.png')
plt.show()

#There was good training along the way, but the model started overfitting at the end.

# import modules
from IPython.display import display, Javascript, Image
from google.colab.output import eval_js
from base64 import b64decode, b64encode
import cv2
import numpy as np
import PIL
from PIL import Image, ImageDraw
import io
import html
import time

# function to convert the JavaScript object into an OpenCV image
def imgFunc(js_reply):
  # decode base64 image
  image_bytes = b64decode(js_reply.split(',')[1])
  # convert bytes to numpy array
  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)
  # decode numpy array into OpenCV BGR image
  img = cv2.imdecode(jpg_as_np, flags=1)

  return img

# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream
def pic_to_bytes(pic_array):
  # convert array into PIL image
  pic_PIL = PIL.Image.fromarray(pic_array, 'RGBA')
  iobuf = io.BytesIO()
  # format pic into png for return
  pic_PIL.save(iobuf, format='png')
  # format return string
  pic_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))

  return pic_bytes

# initialize the Haar Cascade face detection model
face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))

def take_photo(filename='photo.jpg', quality = 0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
  display(js)

  # get photo data
  data = eval_js('takePhoto({})'.format(quality))
  # get OpenCV format image
  img = imgFunc(data) 
  # grayscale img
  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
  print(gray.shape)
  # get face bounding box coordinates using Haar Cascade
  faces = face_cascade.detectMultiScale(gray)
  # draw face bounding box on image
  for (x,y,w,h) in faces:
      img = cv2.rectangle(img, (x,y),(x+w,y+h),(255,0,0),2)
      crop_img = img[y:y+h, x:x+w]
      cv2.waitKey(0)

  # save image
  cv2.imwrite(filename, crop_img)

  return filename

#crops face
try:
  filename = take_photo('photo.jpg')
  print('Saved to {}'.format(filename))
  # Show the image which was just taken.
  display(Image.open(filename))
except Exception as err:
  # Error if webcam is not
  print(str(err))

#if this doesn't work, rerun the cell

path = "/content/drive/MyDrive/Testing/0/234.png"

path = "/content/drive/MyDrive/Testing/3/1006.png"

path = "/content/drive/MyDrive/Testing/5/4444.png"

path = "/content/drive/MyDrive/Testing/6/1587.png"

path = "/content/photo.jpg"

def prepare(path):
  img_array = cv2.imread(path)
  new_array = cv2.resize(img_array, (224, 224))
  new_array = new_array.reshape(-1, 224, 224, 3)
  new_array = new_array/255
  return new_array

predictions = model.predict(prepare(path))

predictions[0]

if (np.argmax(predictions[0]) == 0):
  print("The person is angry!")
if (np.argmax(predictions[0]) == 1):
  print("The person is disgusted!")
if (np.argmax(predictions[0]) == 2):
  print("The person is fearful!")
if (np.argmax(predictions[0]) == 3):
  print("The person is happy!")
if (np.argmax(predictions[0]) == 4):
  print("The person is neutral!")
if (np.argmax(predictions[0]) == 5):
  print("The person is sad!")
if (np.argmax(predictions[0]) == 6):
  print("The person is suprised!")

img = cv2.imread(path)

font_scale = 1.5
font = cv2.FONT_HERSHEY_PLAIN
  
if (np.argmax(predictions[0])==0):
  status = "Angry"
  x, y, w, h = 3,20,0,0
  # Draw black background rectongLe
  # Add text
  cv2.putText(img, status, org=(x + int(w/10),y + int(h/1.5)), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=0.7, color=(255,0,0), thickness=2)



elif (np.argmax(predictions[0]) == 1):
  status = "Disgusted" 
  x, y, w, h = 3,20,0,0
  # Draw black background rectongLe
  # Add text
  cv2.putText(img, status, org=(x + int(w/10),y + int(h/1.5)), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=0.7, color=(255,0,0), thickness=2)


elif (np.argmax(predictions[0]) == 2):
  status = "Fearful" 
  x, y, w, h = 3,20,0,0
  # Draw black background rectongLe
  # Add text
  cv2.putText(img, status, org=(x + int(w/10),y + int(h/1.5)), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=0.7, color=(255,0,0), thickness=2)

elif (np.argmax(predictions[0]) == 3):
  status = "Happy" 
  x, y, w, h = 3,20,0,0
  # Draw black background rectongLe
  # Add text
  cv2.putText(img, status, org=(x + int(w/10),y + int(h/1.5)), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=0.7, color=(255,0,0), thickness=2)

elif (np.argmax(predictions[0]) == 4):
  status = "Neutral" 
  x, y, w, h = 3,20,0,0
  # Draw black background rectongLe
  # Add text
  cv2.putText(img, status, org=(x + int(w/10),y + int(h/1.5)), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=0.7, color=(255,0,0), thickness=2)

elif (np.argmax(predictions[0]) == 5):
  status = "Sad" 
  x, y, w, h = 3,20,0,0
  # Draw black background rectongLe
  # Add text
  cv2.putText(img, status, org=(x + int(w/10),y + int(h/1.5)), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=0.7, color=(255,0,0), thickness=2)

elif (np.argmax(predictions[0]) == 6):
  status = "Suprised" 
  x, y, w, h = 3,20,0,0
  # Draw black background rectongLe
  # Add text
  cv2.putText(img, status, org=(x + int(w/10),y + int(h/1.5)), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=0.7, color=(255,0,0), thickness=2)

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))